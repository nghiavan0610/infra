services:
  # OpenTelemetry Collector - Central hub for all telemetry data
  otel-collector:
    image: otel/opentelemetry-collector-contrib:0.91.0
    container_name: otel-collector
    command: ["--config=/etc/otel-collector-config.yaml"]
    volumes:
      - ./config/otel-collector-config.yaml:/etc/otel-collector-config.yaml
    ports:
      - "${OTEL_GRPC_PORT:-4317}:4317" # OTLP gRPC receiver
      - "${OTEL_HTTP_PORT:-4318}:4318" # OTLP HTTP receiver
      - "${OTEL_METRICS_PORT:-8888}:8888" # Prometheus metrics exposed by the collector
      - "${OTEL_PROMETHEUS_PORT:-8889}:8889" # Prometheus exporter metrics
      - "${OTEL_HEALTH_PORT:-13133}:13133" # Health check
    environment:
      - LOG_LEVEL=${LOG_LEVEL:-info}
    deploy:
      resources:
        limits:
          memory: ${OTEL_MEMORY_LIMIT:-512m}
        reservations:
          memory: ${OTEL_MEMORY_RESERVATION:-128m}
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:13133/"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    restart: unless-stopped
    networks:
      - observability

  # Jaeger - Distributed tracing backend
  jaeger:
    image: jaegertracing/all-in-one:latest
    container_name: jaeger
    environment:
      - COLLECTOR_OTLP_ENABLED=true
      - METRICS_STORAGE_TYPE=prometheus
      - PROMETHEUS_SERVER_URL=http://prometheus:9090
      - LOG_LEVEL=${LOG_LEVEL:-info}
    ports:
      - "${JAEGER_UI_PORT:-16686}:16686" # Jaeger UI
      - "${JAEGER_HTTP_PORT:-14268}:14268" # Jaeger collector HTTP
      - "${JAEGER_GRPC_PORT:-14250}:14250" # Jaeger collector gRPC
      - "${JAEGER_ZIPKIN_PORT:-9411}:9411" # Zipkin compatibility
    deploy:
      resources:
        limits:
          memory: ${JAEGER_MEMORY_LIMIT:-512m}
        reservations:
          memory: ${JAEGER_MEMORY_RESERVATION:-128m}
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:14269/"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    restart: unless-stopped
    networks:
      - observability

  # Tempo - Distributed tracing backend (alternative/complement to Jaeger)
  tempo:
    image: grafana/tempo:2.3.1
    container_name: tempo
    command: ["-config.file=/etc/tempo.yaml"]
    volumes:
      - ./config/tempo-config.yaml:/etc/tempo.yaml
      - tempo-data:/tmp/tempo
    ports:
      - "${TEMPO_PORT:-3200}:3200" # Tempo query frontend
      - "${TEMPO_OTLP_PORT:-4319}:4317" # OTLP gRPC (alternative port)
    deploy:
      resources:
        limits:
          memory: ${TEMPO_MEMORY_LIMIT:-1g}
        reservations:
          memory: ${TEMPO_MEMORY_RESERVATION:-256m}
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:3200/ready"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    restart: unless-stopped
    networks:
      - observability

  # Prometheus - Metrics storage and querying
  prometheus:
    image: prom/prometheus:v2.48.1
    container_name: prometheus
    command:
      - "--config.file=/etc/prometheus/prometheus.yml"
      - "--storage.tsdb.path=/prometheus"
      - "--web.console.libraries=/usr/share/prometheus/console_libraries"
      - "--web.console.templates=/usr/share/prometheus/consoles"
      - "--web.enable-lifecycle"
      - "--storage.tsdb.retention.time=${PROMETHEUS_RETENTION_TIME:-15d}"
    volumes:
      - ./config/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus-data:/prometheus
    ports:
      - "${PROMETHEUS_PORT:-9090}:9090" # Prometheus UI
    deploy:
      resources:
        limits:
          memory: ${PROMETHEUS_MEMORY_LIMIT:-2g}
        reservations:
          memory: ${PROMETHEUS_MEMORY_RESERVATION:-512m}
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:9090/-/healthy"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    restart: unless-stopped
    networks:
      - observability

  # Loki - Log aggregation system
  loki:
    image: grafana/loki:2.9.3
    container_name: loki
    command: -config.file=/etc/loki/local-config.yaml
    volumes:
      - ./config/loki-config.yaml:/etc/loki/local-config.yaml
      - loki-data:/loki
    ports:
      - "${LOKI_PORT:-3100}:3100" # Loki API
    deploy:
      resources:
        limits:
          memory: ${LOKI_MEMORY_LIMIT:-1g}
        reservations:
          memory: ${LOKI_MEMORY_RESERVATION:-256m}
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:3100/ready"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    restart: unless-stopped
    networks:
      - observability

  # Promtail - Log shipper for Loki (scrapes JSON logs from your app)
  promtail:
    image: grafana/promtail:2.9.3
    container_name: promtail
    volumes:
      - ./config/promtail-config.yaml:/etc/promtail/config.yml
      - /var/log:/var/log:ro
      - ./logs:/app/logs:ro
    command: -config.file=/etc/promtail/config.yml
    deploy:
      resources:
        limits:
          memory: 256m
        reservations:
          memory: 64m
    restart: unless-stopped
    networks:
      - observability
    depends_on:
      loki:
        condition: service_healthy

  # Grafana - Visualization and dashboards
  grafana:
    image: grafana/grafana:10.2.3
    container_name: grafana
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_ADMIN_PASSWORD:-admin}
      - GF_SECURITY_ADMIN_USER=${GRAFANA_ADMIN_USER:-admin}
      - GF_USERS_ALLOW_SIGN_UP=${GRAFANA_ALLOW_SIGNUP:-false}
      - GF_LOG_LEVEL=${LOG_LEVEL:-info}
    volumes:
      - grafana-data:/var/lib/grafana
      - ./config/grafana-datasources.yaml:/etc/grafana/provisioning/datasources/datasources.yaml
    ports:
      - "${GRAFANA_PORT:-3000}:3000" # Grafana UI
    deploy:
      resources:
        limits:
          memory: ${GRAFANA_MEMORY_LIMIT:-512m}
        reservations:
          memory: ${GRAFANA_MEMORY_RESERVATION:-128m}
    healthcheck:
      test:
        ["CMD", "wget", "--spider", "-q", "http://localhost:3000/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    restart: unless-stopped
    networks:
      - observability
    depends_on:
      prometheus:
        condition: service_healthy
      loki:
        condition: service_healthy
      tempo:
        condition: service_healthy

networks:
  observability:
    driver: bridge

volumes:
  prometheus-data:
    driver: local
  loki-data:
    driver: local
  tempo-data:
    driver: local
  grafana-data:
    driver: local
